---
title: Agentica > Guide Documents > Plugin Modules > PG Vector Selector
---

# PG Vector Selector

## Introduction

This library was created to significantly reduce token consumption for function selection in Agentica. While the existing Agentica Selector typically consumes a large number of tokens per selection, this library cuts token usage to approximately one-tenth by employing Vector Semantic Search technology.

Vector Semantic Search embeds text into a high-dimensional vector space, enabling searches based on semantic similarity. This approach drastically reduces token consumption compared to traditional keyword-based methods.

The difference in selection speed between using this library and not using it is minimal. However, using this library is approximately 1.3 times faster.

The current state of selection accuracy leaves room for improvement. Contributions to enhance accuracy are welcome. You can experiment with improving tool selection accuracy by using the experimental.[select_prompt](#select_prompt) configuration.


## Installation

```bash copy
npm install @agentica/pg-vector-selector
```

## Usage

Just replace the existing `executor.select` with the `selectorExecute` function.

```typescript copy
import { Agentica } from "@agentica/core";
import { AgenticaPgVectorSelector } from "@agentica/pg-vector-selector";

import typia from "typia";


// Initialize with connector-hive server
const selectorExecute = AgenticaPgVectorSelector.boot<"chatgpt">({
  connectorHiveConnection: {
    host: `http://localhost:${TestGlobal.connectorHivePort}`,
  },
});


const agent = new Agentica({
  model: "chatgpt",
  vendor: {
    model: "gpt-4o-mini",
    api: new OpenAI({
      apiKey: process.env.CHATGPT_API_KEY,
    }),
  },
  controllers: [
    await fetch(
      "https://shopping-be.wrtn.ai/editor/swagger.json",
    ).then(r => r.json()),
    typia.llm.application<ShoppingCounselor>(),
    typia.llm.application<ShoppingPolicy>(),
    typia.llm.application<ShoppingSearchRag>(),
  ],
  config: {
    executor: {
      select: selectorExecute, // Replace the existing selector
    }
  }
});
await agent.conversate("I wanna buy MacBook Pro");
```

### How It Works
`AgenticaPgVectorSelector` converts input text into vectors and uses PostgreSQL's pgvector extension to quickly find the most similar functions. The process works as follows:

1. User input or conversation context is converted into vectors
2. The system searches the database for function vectors most similar to the input
3. The function with the highest similarity score is selected and executed

## Connector-Hive Server Setup

This library depends on the `connector-hive` server. You need to install and run the `connector-hive` server.

Connector-Hive repository: https://github.com/wrtnlabs/connector-hive

### How to run connector-hive

If you don't have a PostgreSQL server with vector extension installed, you can use Docker to run it.

```bash copy
docker run -d \
  --name postgres-vector \
  -e POSTGRES_USER=your_user \
  -e POSTGRES_PASSWORD=your_password \
  -e POSTGRES_DB=your_database \
  -p 5432:5432 \
  pgvector/pgvector
```

Then, set up the environment variables file as follows:

```env copy
// .env
PROJECT_API_PORT=37001
DATABASE_URL=postgresql://your_user:your_password@host.docker.internal:5432/your_database
COHERE_API_KEY=your_cohere_api_key
API_KEY=your_optional_api_key  # Optional: If set, all requests except GET /health must include this key
```

```bash copy
docker pull ghcr.io/wrtnlabs/connector-hive:latest && \
docker run -d \
  --name connector-hive \
  --env-file .env \
  -p 37001:37001 \
  ghcr.io/wrtnlabs/connector-hive:latest
```

Now you can use the `connector-hive` server with the `pg-vector-selector` library:

```typescript filename="src/main.ts" copy
// Connect to connector-hive server running on localhost
const selectorExecute = AgenticaPgVectorSelector.boot<"chatgpt">(
  'http://localhost:37001'
);


const agent = new Agentica({
  model: "chatgpt",
  vendor: {
    model: "gpt-4o-mini",
    api: new OpenAI({
      apiKey: process.env.CHATGPT_API_KEY,
    }),
  },
  controllers: [
    await fetch(
      "https://shopping-be.wrtn.ai/editor/swagger.json",
    ).then(r => r.json()),
    typia.llm.application<ShoppingCounselor>(),
    typia.llm.application<ShoppingPolicy>(),
    typia.llm.application<ShoppingSearchRag>(),
  ],
  config: {
    executor: {
      select: selectorExecute,
    }
  }
});

// Start conversation
await agent.conversate("I wanna buy MacBook Pro");
```

## Experimental Features

### select_prompt

The `select_prompt` configuration allows you to customize the prompt for the function selection process. This can be used to improve the accuracy of tool selection.

```typescript copy
const selectorExecute = AgenticaPgVectorSelector.boot<"chatgpt">({
  connectorHiveConnection: {
    host: `http://localhost:${TestGlobal.connectorHivePort}`,
  },
  experimental: {
    select_prompt:
      "You are an AI assistant that selects and executes the most appropriate function(s) based on the current context, running the functions required by the context in the correct order. First, analyze the user's input or situation and provide a brief reasoning for why you chose the function(s) (one or more). Then, execute the selected function(s). If multiple functions are chosen, the order of execution follows the function call sequence, and the result may vary depending on this order. Return the results directly after execution. If clarification is needed, ask the user a concise question.",
  },
});
```

when get tool list from vector database, it will use the `select_prompt` to select the most appropriate function.
